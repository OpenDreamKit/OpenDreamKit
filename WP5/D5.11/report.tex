\documentclass{deliverablereport}
\usepackage{hyperref}

\deliverable{hpc}{sage-HPCcombi}
\deliverydate{31/08/2018}
\duedate{31/08/2018 (M36)}
\author{V. Delecroix, F. Hivert}

%\usepackage[nottoc, notlof, notlot]{tocbibind}
\usepackage[backend=bibtex]{biblatex}
\addbibresource{report.bib}
\makeatletter\def\blx@maxline{77}\makeatother

\usepackage{multirow}
\usepackage{xcolor,colortbl}
\usepackage{pgfplots}

\usepackage{tikz}
\usepackage{ulem}

\newcommand{\Cilk}{\texttt{Cilk}\xspace}
\newcommand{\CilkP}{\texttt{Cilk++}\xspace}
\newcommand{\CPP}{\texttt{C++}\xspace}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\sgnode}[1]{{\bf \left<#1\right>}}
\newcommand{\gr}[1]{{\color{gray} #1}}

\DeclareMathOperator{\Irr}{Irr}

\newtheorem{defi}{Definition}
\newtheorem{prop}{Proposition}


\setcounter{tocdepth}{1}
\begin{document}
\maketitle

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Computer experimentations in discrete mathematics, in particular
enumerative and algebraic combinatorics, require high performance
computing. The search spaces are often huge and the best algorithmic
strategy for the exploration is not evident and often depend on
the answer to the question being probed. Let us cite the following description
from~\cite{LoidlTrinder-Hecke}:
\begin{quote}{}
  Some discrete mathematical problems are embarrassingly parallel, and this
  has been exploited for years even at Internet scale, \emph{e.g.} the “Great
  Internet Mersenne Prime Search”.  Many parallel algebraic computations
  exhibit high degrees of irregularity, at multiple levels, with numbers and
  sizes of tasks varying enormously (up to 5 orders of magnitude). They tend
  to use complex user-defined data structures, exhibit highly dynamic memory
  usage and complex control flow, often exploiting recursion. They make
  little, if any, use of floating-point operations.  This combination of
  characteristics means that symbolic computations are not well suited to
  conventional HPC paradigms with their emphasis on iteration over floating
  point arrays.
\end{quote}

This deliverable is about experimentations in combinatorics
that involve low-level optimization and parallelization as
well as the integration of these techniques in the computer
algebra system \Sage.

This deliverable has greatly benefited from the \ODK development
workshops \textit{Sage Days 84} held in Olot (Spain) in spring 2017
and \textit{Interfacing (math) software with low level libraries}
held in spring 2018 in Cernay-la-Ville (France).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Two examples from algebra}

To compare computation technologies, our approach was to experiment
them on various problems that require intensive computations. We present two such problems.

\subsection{Counting and enumerating integer vectors}
\label{subsec:intro:integer:vectors}

Integer vectors, that is finite sequences of integers, are central
in combinatorics as they can be used to encode many different
objects. In each situation the integer vectors are subject to various
constraints such as:
\begin{itemize}
\item linear constraints (e.g. lower or upper bounds on the entries,
maximum differences between adjacent positions, etc.)
\item restrictions on the content (e.g. each value should be used
at most once)
\item symmetries (e.g. lexicographically smallest among all possible
cyclic permutations).
\end{itemize}
One algorithmic problem in combinatorics is trying to provide
efficient enumeration of integer vectors subject to these kinds of
constraints.

For example, permutations of $\{1, \ldots, n\}$ are encoded by integer vectors
on $\{1, \ldots, n\}$ for which each entry appears exactly once. In a sample
\Sage session the list can be obtained as follows:
\begin{verbatim}
sage: P = Permutations(3)
sage: P.list()
[[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1],
 [3, 1, 2], [3, 2, 1]]
\end{verbatim}
Other elementary examples include integer partitions
\begin{verbatim}
sage: Partitions(5).list()
[[5], [4, 1], [3, 2], [3, 1, 1], [2, 2, 1], [2, 1, 1, 1],
 [1, 1, 1, 1, 1]]
\end{verbatim}
or Lyndon words
\begin{verbatim}
sage: LyndonWords(2,4).list()
[word: 1112, word: 1122, word: 1222]
\end{verbatim}

Sometimes, one just wants to count the number of objects in some set and possibly
avoid generating the complete list. In \Sage, access to this
counting is often implemented by a {\tt cardinality()} method, the
implementation of which can often be different from the implementation for
enumerating the objects themselves:
\begin{verbatim}
sage: Permutations(30).cardinality()
265252859812191058636308480000000
sage: Partitions(1000).cardinality()
24061467864032622473692149727991
sage: LyndonWords(2, 120).cardinality()
11076899964874298931257370467884546
\end{verbatim}

In this deliverable we will demonstrate how the interface to the LaTTe package
in \Sage allows more efficient counting and how Cython has helped faster enumeration
in \Sage. We will also present some promising experiments involving among
other things vectorization techniques (MMX, SSE and AVX instruction sets) and
shared memory multicore computing with \CilkP.

\subsection{Numerical semigroups}

A computation involving numerical semigroups is known as Frobenius coin
problem. Given a set of coins of specifified denominations, it asks what is
the largest monetary sum that {\em cannot} be obtained using only coins in that
set. Formally,
\begin{defi}
  A \emph{numerical semigroup} $S$ is a subset of $\NN$ containing $0$, closed
  under addition and of finite complement in $\NN$.
\end{defi}
For example the set $S_E=\{0,3,6,7,9,10\}\cup\{x\in\NN, x\geq 12\}$
is a numerical semigroup. One challenging problem in the field of
semigroup analysis is to count numerical semigroups under certain
constraints. To state the question precisely we need a little
terminology:
\begin{defi}
  Let $S$ be a numerical semigroup. We call the \emph{genus} of $S$ the
  cardinality of the complementary set $g(S)=\operatorname{card}(\NN\setminus
  S)$.
\end{defi}
For example the genus of the previous example $S_E$ is $6$, the cardinality of
$\{1,2,4,5,8,11\}$.

For a given positive integer $g$, the number of numerical semigroups of genus
$g$ is finite and is denoted by $n_g$. In J.A. Sloane's \emph{on-line
encyclopedia of integer sequences}~\cite{OEIS} we find the values of $n_g$
for $g\leq 52$. These values were obtained by M. Bras-Amor\'os~\cite{BrasAmoros2008}. It is conjectured that the number of
those semigroups grows exponentially with the genus $g$. So it makes it both interesting and hard
to get further values of $n_g$ by directly enumerating semigroups.

Using adequate data structures and parallelization with \Cilk allowed
F.~Hivert with his collaborator J.~Fromentin to obtain the number of numerical
semigroups up to genus $g \leq 70$ and also to confirm for $g\leq 60$ another
unrelated famous conjecture due to Wilf~\cite{Wilf}. This work has led to the
publication~\cite{FromentinH16}.

We would like to explain why exploring this tree is quite challenging as a
parallel problem. The computation for $g=70$ involves exploring an extremely
large tree with $10^{15}$ nodes. Of course, when exploring such a tree,
different branches can be explored in parallel. However, if the tree is
unbalanced, we need a mechanism to rebalance the computation. It appears that
the tree of numerical semigroups is extremely unbalanced and is therefore a good
prototypical challenge for such a computation. For example, the number of nodes at depth 30 and 45
are $5\,646\,773$ and $8\,888\,486\,816$ respectively. If we sort the nodes
at depth $30$ decreasingly by their number of descendants at depth $45$, then
\begin{itemize}
\item The first node has $42\%$~of the descendants;
\item The second node has $7.5\%$~of the descendants;
\item The $1000$~first nodes have $99.4\%$~of the descendants;
\item Only $27\,321$ nodes have descendants at depth~$45$;
\item Only $257$ nodes have more than $10^6$~descendants.
\end{itemize}
As a consequence, any
naive embarassingly parallel algorithm is doomed, as the majority
of the time may be spent in just a few branches. There must be
some non-trivial load balancing to achieve good performance.  We will discuss the
different technologies to solve this problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\subsection{Classes of problems appearing in algebra and combinatorics}

In our experiments, we have identified the following four kinds of problems:
\begin{enumerate}
\item\label{enum-flat} \emph{Embarrassingly parallel problems}: where
  little or no effort is needed to separate the problem into a number of
  parallel tasks.
\item\label{enum-tree} \emph{Recursive parallel problems}: the computational
  problem is organized as a recursive tree which can be discovered on the fly
  during the computation.
\item\label{enum-graph} \emph{Recursive redundant parallel problems}: this
  kind of problem is similar to the previous one except that instead of a
  tree, the computational problem is organized as a (directed acyclic) graph
  so that they are multiple different way to reach the same computation. So the
  computing units have to coordinate to avoid recomputing the same node too
  many times or to detect that all its prerequisites are already comparted.
\item\label{enum-micro} \emph{Micro data structure parallel optimization}:
  for many combinatorial structures (permutations, partitions, monomials, Young
  tableaux), their data can be encoded as a small sequence of small integers
  that can often be handled efficiently by a CPU thanks to vector instructions.
\end{enumerate}
In this work we have mostly focused on point (\ref{enum-tree}) and
(\ref{enum-micro}) as (\ref{enum-flat}) is easy and (\ref{enum-graph}) cannot
be solved without a good solution for (\ref{enum-tree}) which is still
problematic.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{An overview of techniques and technologies}

Before going deeper into the details of this deliverable it is important to
draw a general picture of the algorithmic techniques and the hardware and
software technologies available.

Let us first distinguish the following two families of programming
languages. On the one hand there are the interpreted languages
such as \Python or Julia. On the other hand we have the compiled languages
such as C/C++. The former languages are very convenient for end-users as
they provide high level data structures and instructions as well as automatic
memory management. This is one of the reasons why \Python was chosen as the
base language for \Sage. However, these higher level languages tend to be less
performant than low-level languages, especially when large
iterations have to be performed. In this situation, it is necessary to
investigate the details of memory allocation and CPU instructions. 

A first ingredient of optimization that provides a bridge between interpreted
and compiled language is provided by \Cython, a Python
to C/C++ compiler. \Cython plays an important role in this deliverable in two
different ways. First, by replacing Python code with Cython code, which generally results
immediately in faster code. Second, by developing interfaces to C/C++ libraries.

The use of a low-level language such as C/C++, provides the programmer with a
first level of in-core
parallelization: the CPU vectorized
instructions, i.e. single instructions operating on vectors of multiple
data (SIMD). These instructions are also of critical importance for efficient
linear algebra algorithms as implemented in the \Linbox library. The relevance
of these instructions in the context of combinatorics is discussed in
Section~\ref{subsec:combi:SIMD}. 

The second level of parallelization concerns multi-core computations. This is
conveniently handled by language extensions such as Open MP, Threading 
Building Block (TBB) or \Cilk. At this level one important ingredient in
optimization is the careful usage of shared memory.  Before getting into
technical details, we recall in subsection~\ref{subsec:map-reduce:Sage} the
small framework that was implemented in \Sage
during~\longdelivref{hpc}{sage-paral-tree} that also illustrates the typical
problem one faces in combinatorics. More details on the usage of \Cilk are
provided in Section~\ref{sec:low:level}.

The last level of parallelism concerns computations with multiple nodes
(e.g.~multiple computers on a network) and is not addressed by this
deliverable.

\subsection{Map-reduce and its implementation in \Sage}
\label{subsec:map-reduce:Sage}

The aim of this section, is to present an example of a typical end-user feature we would like
to be able to provide as an actual HPC component. This is a solution for
type~(\ref{enum-tree}) problems in our classification.

Map-reduce is a general programming model that is shared by
parallelized solutions to many problems and is relevant to our situation. In this section we
present a small framework implemented in Sage~\cite{sage} which enables
efficient map/reduce-like computations on
large recursively defined sets. Map-reduce is a classical programming model
for distributed computations where one maps a function on a large data set --
applying the same function to each element of the data set -- then
uses a ``reduce'' function to summarize all the ``map'' results. It has a
large range of intensive applications in combinatorics:
\begin{itemize}
  \item Compute the cardinality;
  \item More generally, compute any kind of generating series;
  \item Test a conjecture: i.e. check that all elements of $S$ satisfy a specific
    property, or provide a counter example;
  \item Count/list the elements of $S$ having this property.
\end{itemize}
Use cases in combinatorics often have two specificities. First of all, due to
combinatorial explosion, sets often do not fit in the computer's memory or
disks and are enumerated on the fly. Then, many problems are flat, leading to
embarrassingly parallel computations which are easy to parallelize. However, a
second very common use case is to have data sets that are described by a
recursion tree which may be heavily unbalanced (as with numerical semigroups
described in the previous section).

The framework~\cite{map-reduce} we developed works on the following input:
A \textbf{recursively enumerated set} given by:
\begin{itemize}
\item the \texttt{roots} of the recursion
\item the \texttt{children} function computing the next level of the recursion
\item the \texttt{post\_process} function, which can also filter intermediate nodes
\end{itemize}
Then, a \textbf{map-reduce problem} is given by:
\begin{itemize}
\item the \texttt{map} function
\item the \verb|reduce_init| function, which specifies an initial value for
    the reduction process
\item the \texttt{reduce} function
\end{itemize}
Here is an example where we count binary sequence of length 15:
\begin{verbatim}
sage: S = RecursivelyEnumeratedSet( [[]],
....:   lambda l: [l+[0], l+[1]] if len(l) <= 15 else [],
....:   post_process = lambda x : x if len(x) == 15 else None,
....:   structure='forest', enumeration='depth') 
sage: sage: S.map_reduce(
....:   map_function = lambda x: 1,
....:   reduce_function = lambda x,y: x+y,
....:   reduce_init = 0 )
32768
\end{verbatim}
This framework uses a multi-process implementation of a work-stealing
algorithm~\cite{BlumofeL99, BlumofeL99} meaning that if the work is divided
unevenly between processes, then when one process becomes idle it can ``steal''
work from another process's work queue. In the above example of binary
sequences it scales as follows
\[\begin{tabular}{ccccccccccccccc}
\# processors & 1 & 2  & 3 & 4 & 6 & 8 & 12 & 16 & 24\\
Time (s)      & 132.0 & 66.0 & 47.2 & 36.5 & 26.2 & 21.5 & 15.1 & 12.9 & 9.6
    \\
Speedup & 1.0 & 2.0 & 2.8 & 3.6 & 5.0 & 6.1 & 8.7 & 10.2 & 13.8 \\
\end{tabular}
\]
As can be seen on this sample the scaling is not linear with the number of
cores. The problem here is that the size of the computation in each node is
very small (prepending a integer to a list). As a consequence Python's
overhead is non negligible. Here is a more realistic example where each node
takes typically $1$~ms:
\[\begin{tabular}{ccccccccccccccc}
\# processors & 1 & 2  & 3 & 4 & 6 & 8 & 12 & 16 & 24\\
Time (s)      & 237.0 & 124.0 & 83.0 & 65.0 & 46.2 & 35.2 & 23.5 & 18.4 & 12.8
    \\
Speedup & 1.0 & 1.9 & 2.9 & 3.6 & 5.1 & 6.7 & 10.1 & 12.9 & 18.5
\end{tabular}
\]

This is still not linear but better. The remaining overhead is explained by the increase of job 
stealing coming with parallelization, especially in a multi-process
context. A challenge will be to reduce this overhead and achieve
linear scaling.

Nevertheless this framework enabled researchers in mathematics to conduct
dozens of experiments in areas ranging from
Coxeter group and representation theory of semigroups, to the combinatorial study
of the C3 linearization algorithm used to compute the method resolution order
(MRO) in languages such as \Python and Perl~\cite{C3-controled}.

\section{Low-level experiments}
\label{sec:low:level}

We now present the result of the evaluation of various parallelization
technologies applied to algebraic combinatorics computations.

\subsection{Combinatorial structures and vector instructions}
\label{subsec:combi:SIMD}

Current SIMD instruction sets were introduced
in three stages: MMX (Single Instruction Multiple Data instruction set
introduced in 1997), SSE (Streaming SIMD Extensions, introduced in 1999) and
more recently AVX (Advanced Vector Extensions, introduced in 2008).

In many combinatorial structures (permutations, partitions, monomials, Young
tableaux), the data can be encoded as a small sequence of small integers that
can often be handled efficiently thanks to these vector instructions. For
example, on current desktop CPU architectures ({\texttt x86}), small
permutations ($N\leq 16$) are very
well handled. Indeed, thanks to machine instructions such as \verb+PSHUFB+ (Packed
Shuffle Bytes), applying a permutation on a vector only takes a few CPU cycles.  Here
are some examples of operations with their typical speedups via SIMD instructions:
\[
\begin{tabular}{l|c}
Operation & Speedup \\\hline
Sum of a vector of bytes & $3.81$\\
Sorting a vector of bytes& $21.3$\\
Inverting a permutation& $1.97$\\
Number of cycles of a permutation& $41.5$\\
Number of inversions of a permutation& $9.39$\\
Cycle type of a permutation& $8.94$\\
\end{tabular}
\]
Unfortunately, from a developer's point of view, this requires rethinking all
the algorithms, and there is nearly no support from the compiler for
automating this task.\bigskip

As a part of the OpenDreamKit deliverable, we started to develop a new
library called \texttt{HPCombi}\footnote{\url{https://github.com/hivert/HPCombi}}. The
goal is to use SSE and AVX instruction sets for very fast manipulation of
combinatorial objects of small sizes. It is still in an experimental stage and
currently deals only with permutations, transformations and partial
transformations. We also have experimental code for partitions and boolean
matrices.

Despite its infancy the code is already used by
libsemigroups~\cite{libsemigroups} (which deals with a different kind of
semigroup from numerical semigroups) by James Mitchell. It is a C++ library
for semigroups and monoids using C++11, and is used in the Semigroups package
for GAP. The development version is available on \GitHub, and there are Python
bindings which makes it usable from \Sage. The development of a more thorough
\Sage interface is planned.  \bigskip

Finally, we want to stress out that this is actually a research
problem, as nearly no classical combinatorial algorithm was conceived 
with vector instructions in mind. And indeed, except for sorting a vector where we used 
a classical sorting network algorithm, all the operations in the previous table of 
operations required the design of a new algorithm. For example, for the
simple task of inverting a permutation, we designed four different new
algorithms:
\begin{itemize}
\item \verb|inverse_sort|:  a classical sort algorithm
\item \verb|inverse_search|:  using parallel binary
  search. Limited by the current size of vector registers ($16$~bytes) which support
  arbitrary array manipulation (in particular the shuffle instruction), it is
  not the fastest algorithm. Yet it is the only one of {\em logarithmic} complexity,
  so it should become the fastest if and when a CPU supporting larger registers
  for this instruction become available;
\item \verb|inverse_power|: a binary powering algorithm;
\item \verb|inverse_cycle|: using the cycle decomposition. It is currently the fastest.
\end{itemize}
Preliminary results from this work were presented as a keynote invited talk at
the 8th International Workshop on Parallel Symbolic Computation (PASCO 2017),
Kaiserslautern, Germany, July 23-24, 2017 and at the Scottish Programming
Languages Seminar, 5th June 2018, Heriot-Watt University. A research paper on
this subject is in preparation as a result of this work.

\subsection{Combinatorial structures and GPU computations}

In the previous section we presented how the vector instruction of modern
CPUs enabled a large speedup for small combinatorial objects. The main
requirement is that the datastructure fits in one or a
handful of the CPU registers (data storage areas internal to the CPU, where
intermediate results of computations are stored). However, while this
covers a lot of practical case on algebraic combinatorics,  there is sometimes a
need for larger combinatorial objects, due to combinatorial
explosion. One lead was to investigate if graphics
processing units (GPUs) could speed up these kinds of computations. Our benchmark was to write a
toy implementation of the algorithm used in libsemigroups~\cite{libsemigroups}
replacing the use of HPCombi and AVX CPU vector instruction by some GPU
code. These algorithms enumerate the elements of a transformation of semigroups.

This kind of computation typically involves the repetition of two computation
stages:
\begin{enumerate}
\item compute the composition of large functions on a discrete set;
\item store them in a hash table to remove duplicates.
\end{enumerate}
It should be noted that the first stage doesn't require any arithmetic, but
amount to shuffling large chunks of data in memory. This is a very atypical usage of a
GPU which is tailored to do arithmetic on larger vectors of floating point numbers, and it was very difficult
to predict the behavior. One expected cause of this inconsistency is the communication time
between the CPU and the GPU.
\medskip

The outcome of the experiments lead by Daniel Vanzo (research engineer at
LRI/UPSud) under the supervision of Florent Hivert were that:
\begin{itemize}
\item Composition of large functions can be greatly accelerated (typically
$\times 100$) by the GPU, \emph{provided} that the CPU ask the GPU to perform
enough of them (more than 1K) at once.
\item The same is true for the computation of hash values.
\end{itemize}
Although this requirement seems reasonable for the first stage, it is not for
the second: a reasonable use case of ours required the storage of the results of the
computation in a large hash table which typically is at the limit if not
larger than the size of the GPU's memory. We  therefore had to keep the hash table
in the computer's main memory, outside the GPU. This degraded performance due to
random memory accesses: Nearly all
memory accesses triggered a cache miss which resulted in slowdowns up to
$60\times$. \bigskip

The conclusion is that in order to achieve a useful speedup with the GPU, the entire computation
must be hosted inside the GPU's internal memory. This has two very important drawbacks:
\begin{itemize}
\item It drastically limits the size of the computation as CPU memory tends to
  be around $10\times$ larger than the GPU's.
\item Since GPU programming is not a widespread skill, it forces us to write
  seemingly black-box, monolithic algorithms.
\end{itemize}
This second point doesn't fit well within the research-driven use cases
in the framework of the OpenDreamKit project; that is, it is difficult to understand
or modify by a typical researcher. % Note: I added an additional clause here, clarifying what I think you meant.
We think that this technology is not directly applicable in algebraic combinatorics
in general. However, it remains interesting
for very specific computations where we are ready to pay the price of writing
bespoke and poorly reusable programs.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% \subsection{Integer vectors up to permutations}
% \label{subec:integer:vectors}

% We briefly report a successful optimization using the technologies
% evoked in the previous section. The aim was to optimize an algorithm
% developed by N.~Borie for enumerating integer vector modulo permutation
% groups~\cite{Borie}.

% The problem is the following: we are given a subgroup $G$ of the symmetric
% group $S_n$. It acts by permutation of coordinates on the vectors in $\NN^n$.
% The problem is to generate one vector in each orbit. Note that there are
% infinitely many such vectors; in practice one usually wants to enumerate the
% vectors with a given sum or content. 

% N.~Borie designed a tree structure on those vectors which allows to enumerate
% them recursively. At the level of each node, a relatively complicated
% computation is done involving partial lexicographic comparison and a hash
% table to avoid some duplication. The goal was to optimize the particular case
% of small groups where $n\leq16$. The development went along the following
% steps:
% \begin{itemize}
% \item permutation, vectors and lexicographic comparison using vector
%   instructions;
% \item recursive enumeration using \CilkP
% \item used thread local strorage for the hash table at the level of each node
% \item designed a handmade hash table to avoid dynamic allocation and adapted
%   to the specific use-case
% \end{itemize}
% This last step is due to a very specific use case for the hash table: we
% needed it to store a dynamic set where we only add elements and never remove
% one, and we clear the hash table very often. Profiling showed that the hash
% table may grow up to thousand of elements but, on the average, is
% only cleared when containing $2.5$~elements ! We decided therefore to use a
% closed bounded hash table together with a linked list of used buckets to be
% able to clear the table quickly.

% Altogether, we compared our optimized version with an already optimized
% non-parallel compiled version using the \Python compiler Cython. Computing the
% $375810$~integer vectors of sum 25 for the largest transitive subgroup of
% $S_{16}$ took $9$min $23$s on a single core with Sage's code, whereas our code
% is able to do it in $0.503$s on $8$~cores for a speedup of $1112$ times.
% Finally, the code (not yet released) is downloadable at~\cite{IVMPG}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Numerical semigroups}
\label{subsec:numerical-semigroups}

The computation of numerical semigroup is a good challenge for large tree
explorations (case (\ref{enum-tree}) in our
classification). Different branches of the
tree can be explored in parallel by different CPU cores. The
delicate part is to ensure that all cores are working,
i.e. always have a new branch to explore.

What makes this problem particularly difficult is the size of the
trees (typically up to $10^{15}$ in our experiments) and the granularity of the
computation (typically only $10-50$ns is spent on each tree node). This is
extremely demanding on the load balancing algorithms and their implementations.

The clear algorithmic solution is to use work stealing algorithms as
described in~\cite{10.1109/SFCS.1994.365680, BlumofeL99}. Let us recall
that a prototypical Python implementation with a map-reduce fronted
is in Deliverable~\delivref{hpc}{sage-paral-tree}~\cite{map-reduce}. However, it
was clear from the beginning that this 
implementation was a tool to help rapid prototyping in day-to-day research,
but it was not meant for a high performance computing use case. Hence, we had
to experiment with a few lower-level technologies. We present them here together with their
behavior in our prototypical examples:
\begin{itemize}
\item The \CilkP~\cite{CilkIntel} technology is particularly well suited for
  those kinds of problems. For our computation, we used the free version which
  is integrated into the GNU~C compiler~\cite{GCCcilk} since version 5.8.

  \Cilk is a general-purpose language designed for multithreaded parallel
  computing. The \CPP incarnation is called \CilkP. The main principle
  behind the design of the \Cilk language is that the programmer should be
  responsible for \emph{exposing} the parallelism, identifying elements that
  can safely be executed in parallel; the run-time environment decides during
  execution how to actually divide the work between CPU cores. The parallel
  features of \CilkP are used mainly through the \texttt{cilk\_spawn} keyword:
  used on a procedure call, it indicates that the call can safely operate in
  parallel with the remaining code of the current function. Note that the
  scheduler is not obliged to run this procedure in parallel; the keyword
  merely alerts the scheduler that it can do so.

  Overall, this makes \CilkP very easy to use, with short and very readable
  source code. Moreover, it turns out that \CilkP is extremely good at solving
  the problems we were interested in. Here are some figures illustrating the performance we managed
  to achieve in counting semigroups. We performed a full exploration of the tree up to a depth of~$70$ on
  a $32$~core Haswell CPU at $2.3$~Ghz. The number of semigroups at depth $70$ is
  $1607394814170158$.  It tooks $2.528\cdot10^{6}~s$ ($29$~days and $6$~hours)
  exploring $2590899247785594=2.59\cdot10^{15}$ semigroups at a rate of
  $1.02\cdot10^{9}$ semigroups per second. Each semigroup is stored in
  $240$~bytes. Storing all the computed semigroups would take
  $6.22\cdot10^{17}$~bytes of data, which means that we generated
  $2.46\cdot10^{11}$~bytes of data per second.

  The main drawback, is that both Intel and the GCC team decided
  to \textbf{deprecate and no longer maintain the \CilkP extension}. So we
  looked for alternatives.


\item \emph{OpenMP} (Open Multi-Processing) is an application programming
  interface (API) that supports multi-platform shared memory multiprocessing
  programming in C, C++, and Fortran. It consists of a set of compiler
  directives, library routines, and environment variables that influence
  run-time behavior. It allows to spawn tasks using special pragma directives on the
  compiler.

  Unfortunately, for computations like numerical semigroups, there
  is a huge number of small tasks that are spawned. We used the implementation
  from the GCC compiler. At the time of our experiment, we found that the
  scheduler doesn't scale to this huge number of tasks required. The scheduling overhead
  was several order of magnitude larger than \CilkP making it unusable for
  these kinds of computations.

\item Intel's \emph{Threading Building Blocks} is a C++ template library
  developed by Intel for parallel programming on multi-core processors. Using
  TBB, a computation is broken down into tasks that can run in parallel. The
  library manages and schedules threads to execute these tasks.

  However, it suffers exactly the same problem as OpenMP: the scheduler
  does not scale for huge numbers of tasks. Intel's FAQ reads, ``A good rule of
  thumb is that an Intel TBB application should have approximately 10 tasks
  for every worker.'' Similarly, in \cite{LuLi}, they consider a problem
  requiring micro-task computations of roughly 30k tasks, each of which takes 4k
  CPU cycles. Whereas in the numerical semigroup problem task takes around 60
  CPU cycles, the number of tasks easily exceeds 1 billion for a 1 minute long
  computation.

\item Developping efficient scheduler able to deal with very large amount of
  lightweight tasks is an active research area. For instance the ongoing PhD
  thesis by Blair Archibald under the supervision of Phil Trinder at University
  of Glasgow aims to distribute tasks on a cluster
  of machines. As a result, they developed a C++ library called
  YewPar~\cite{YewPar} which they present as ``A Collection of High
  Performance Parallel Skeletons for Tree Search Problems'' using the well
  established HPX~\cite{HPX} parallel library/runtime.

  By the time we got in contact with them, they had already decided to use our numerical
  semigroup algorithm as a benchmark for their scheduling implementation. We
  think that this is a good indication that our choice was correct. Though not
  as easy as \CilkP, the YewPar's integration
  provides distribution across several machines. If only used on
  one multicore machine, YewPar is more or less only $2.5$ times slower than
  \CilkP. The main question is long term maintenance: the website says ``This
  library is currently experimental and should be considered very unstable,''
  and being the work of a PhD student, there is no warranty that it will
  still be maintained in a few years.

\item We also advised three master student interns; namely, Adrien Pavão,
  Thomas Foltête, and Edgar Fournival to explore the Spark technology and the
  Go language. It turned out that these technologies were not a good fit for our
  needs. On the other hand, their work led to discovery of a basic bug in the GCC
  implementation of \CilkP \cite{gcc-bug-80038}.
\end{itemize}

In conclusion, for large combinatorial tree explorations our current
recommendation is to use \CilkP which is both very efficient and simple to use
and learn. We hope that an eventual alternative will manage to achieve similar
performance. A promising newcomer is the Cilk Hub initiative\footnote{\url{http://cilk.mit.edu/}}
to pursue the development of Cilk under a new project, but we have not yet had the occasion to seriously
experiment with it.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Improvements to the \Sage platform}


\subsection{Polytopes and linear programming}
\label{subsec:polytopes}

As mentioned in the introduction, see~\ref{subsec:intro:integer:vectors},
integer vectors are omnipresent in combinatorics. In many situations,
the combinatorial constraints are linear equalities or inequalities.
For example, the partitions of $n$ are given by non-negative integer
vectors $(x_1, \ldots, x_n)$ in $\mathbb{R}^n$ so that $x_1 \geq x_2 \ldots x_n$.
In other words, some general linear programming techniques come into
play. Improving \Sage's capabilities in polytope computations and linear algebra
is critical for combinatorics.

Many libraries, often written in C/C++ exist and one of our tasks was to
create or improve the existing \Sage interfaces to those libraries. Most of these interfaces
rely on Cython to provide a bridge between \Python and C/C++. Let
us mention the creation of the stand-alone library pplpy~\cite{pplpy-code} which now provides
access to the PPL library to any Python user, and is integrated into \Sage.

At a higher level of interaction, an interface to LaTTe in \Sage has
been developed (see trac tickets~\cite{trac-18211}
and~\cite{trac-22497}). It allows efficent counting of
integral points in polytopes. The interface is completely transparent to the
user as can be seen in the following Sage session:
\begin{verbatim}
sage: n = 10
sage: I1 = [[0] + [0]*i + [1] + [0]*(n-1-i)
....:       for i in range(n)]
sage: I2 = [[0] + [0]*i + [1,-1] + [0]*(n-2-i)
....:       for i in range(n-1)]
sage: P = Polyhedron(ieqs=I1 + I2, eqns=[[-n] + [1]*n])
sage: P.integral_points_count()
42
\end{verbatim}
Let us also mention the \Sage interface to the Polymake
software~\cite{polymake-code} which allows direct interaction from
\Sage. Polymake is a reference software for Polyhedral computations
and its inclusion in \Sage has been greatly beneficial.

Polyhedral computations are not restricted to rational numbers. For a long time
floating point polyhedral libraries have existed. However, they are often not
satisfactory, as floating-point rounding errors can lead to subtle contradictions. In the framework
of \ODK, V.~Delecroix started a C/C++ library for computations with embedded
number fields called e-antic~\cite{eantic-code}. It allows exact computations
over algebraic numbers. This has successfully been included in the
Normaliz~\cite{normaliz-code} software and it is now possible to use
it to very efficiently construct polytopes over number fields. We aim to
finalize the inclusion of this code and provide a \Sage interface to it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Cythonization of combinatorics code}

A huge amount of code in \Sage is written in plain Python; this is in
particular true for a large amount of the combinatorics code. Thanks to
Cython, one can easily gain speed-up in computations. A lot of effort has
been made to improve the performance of the current code. We emphasize
some of the efforts that has been made in \ODK.

Two examples of successful ``cythonization'' were achieved for
permutations~\cite{trac-23734} and Lyndon words~\cite{trac-26111}.
These combinatorial objects were already mentioned in the
introduction; see~\ref{subsec:intro:integer:vectors}.
The challenge was to write iterators with maximal efficiency
together with a simple Python wrapper intended for \Sage users.
While in both situations presented here, efficient algorithms exist
we have focused on three levels of optimization:
\begin{itemize}
\item \textit{basic cythonization}. Cython does a decent job in
direct optimization with little human intervention. 
\item \textit{in-place iteration}. As already mentioned, combinatorial objects are typically represented by
integer vectors. Dealing with a lot of plain lists in Python has a huge
cost in memory allocation. The most natural workaround is to provide an in-place
iterator, that is an iterator which modifies the data without creating new objects.
\item \textit{use C arrays}. Finally, using a Python data structure closer to C
arrays than Python's built-in ``list'' type enables the gain of another speedup factor.
\end{itemize}
Below we present simple timings of the iteration through all permutations
of $\{1, 2, \ldots, n\}$ with three runs of the same algorithm. It consists
in modifying a given permutation into the next one for the lexicographic
order. The three columns represent the different versions: in Python
using Python lists, in Cython using Python lists and finally in Cython
using C arrays.
  \begin{center}
\begin{tabular}{c|c|c|c}
    n & Python & Cython on lists & Cython on arrays \\
\hline
9  & 410ms   & 55ms  & 37ms \\
10 & 2.9s    & 309ms & 163ms \\
11 & 32s     & 3.2s  & 1.68s \\
12 & $>$ 2 min & 36.3s & 19.5s \\
\end{tabular}
  \end{center}
These experiments show a near 10x speedup when passing to Cython (with almost no
modification), then Using arrays instead of lists provides an additional 2x speedup.

Let us also mention a slightly different work related to combinatorics:
Dancing links is the name of an algorithm that finds all solutions to
the so-called exact cover problem. It can efficiently be used to
solve tiling problems. Using an embarrassingly parallel method,
this naive parallelization approach allowed us to obtain the list
of solutions 2 to 3 times faster using a 4 core machine
(see~\cite{trac-25125}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}
\Sage is a general purpose computer algebra system with a lot of code related
to combinatorics. The Python language has some weaknesses regarding speed and the
aim of the deliverable was to circumvent these weaknesses. As we demonstrated,
using Cython and careful memory usage allows us to provide an
important speed up in enumeration. Cython is at the same time an ideal
tool to provide access to efficient implementations in C/C++ from Python.

Very promising experimentations have been performed in C regarding the usage
of vectorized operations (SIMD) as well as efficient parallelization. We will
pursue the development of the HPCombi library with the aim to get it
integrated into different computer algebra system such as \Sage and \GAP.

\printbibliography

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

